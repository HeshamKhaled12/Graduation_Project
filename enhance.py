# -*- coding: utf-8 -*-
"""enhance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_z5Vivy4PX4UwPqsTZttatcy0efI40i4
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ai-forever/Real-ESRGAN.git
# %cd Real-ESRGAN

!pip install -r requirements.txt

!mkdir weights
!wget -P weights https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth

!pip install basicsr facexlib gfpgan numpy opencv-python yapf lmdb
!pip install torch torchvision torchaudio

!pip install -e .

!pip install huggingface-hub==0.25.2

import cv2
import numpy as np
import torch
import os
from RealESRGAN import RealESRGAN
from PIL import Image
from tqdm import tqdm

# Load the model
model_path = "weights/RealESRGAN_x4.pth"
device = "cuda" if torch.cuda.is_available() else "cpu"
model = RealESRGAN(scale=4, device=device)
model.load_weights(model_path)

# Input and output paths
video_path = "/content/v.mp4"
output_video_path = "upscaled_video.mp4"

# Create a directory to store frames
os.makedirs("frames", exist_ok=True)

# Extract frames from video
cap = cv2.VideoCapture(video_path)
frame_rate = int(cap.get(cv2.CAP_PROP_FPS))
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) * 4  # Upscaled width
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * 4  # Upscaled height
fourcc = cv2.VideoWriter_fourcc(*"mp4v")  # Codec for output video
out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))

frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Convert frame to PIL Image
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    input_image = Image.fromarray(frame_rgb)

    # Upscale frame
    output_image = model.predict(input_image)

    # Convert back to OpenCV format
    output_frame = cv2.cvtColor(np.array(output_image), cv2.COLOR_RGB2BGR)

    # Write frame to output video
    out.write(output_frame)

    frame_count += 1
    print(f"Processed frame {frame_count}", end="\r")

# Release resources
cap.release()
out.release()
print("Upscaling complete. Output saved as:", output_video_path)

from RealESRGAN import RealESRGAN

from PIL import Image

# Load the model
model_path = "weights/RealESRGAN_x4.pth"
# Provide the device argument, e.g., 'cpu' or 'cuda'
model = RealESRGAN(scale=4, device='cuda')  # Added device='cuda'
model.load_weights(model_path) # Load weights using this method

# Load an input image
input_image = Image.open("/content/s.jpg").convert("RGB")

# Upscale the image
output_image = model.predict(input_image)

# Save and display
output_image.save("upscaled_image.jpg")
output_image.show()