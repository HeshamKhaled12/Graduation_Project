# -*- coding: utf-8 -*-
"""Real_ESRGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zXjXuBgvWrvh5n5BUkkAgPeyvJNBig8A
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ai-forever/Real-ESRGAN.git
# %cd Real-ESRGAN

from google.colab import drive
drive.mount('/content/drive')

!pip install -r requirements.txt

!mkdir weights
!wget -P weights https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth

!pip install basicsr facexlib gfpgan numpy opencv-python yapf lmdb
!pip install torch torchvision torchaudio

!pip install -e .

!pip install huggingface-hub==0.25.2

import cv2
import numpy as np
import torch
import os
from RealESRGAN import RealESRGAN
from PIL import Image
from tqdm import tqdm

# Load the model
model_path = "weights/RealESRGAN_x4.pth"
device = "cuda" if torch.cuda.is_available() else "cpu"
model = RealESRGAN(scale=4, device=device)
model.load_weights(model_path)

# Input and output paths
video_path_1 = "/content/drive/MyDrive/video enhance/y2mate.com - Drone Detection_360P.mp4"
output_video_path = "upscaled_video_1.mp4"

# Create a directory to store frames if needed (not used in this example, but useful for debugging)
os.makedirs("frames", exist_ok=True)

# Extract frames from video
cap = cv2.VideoCapture(video_path_1)
frame_rate = int(cap.get(cv2.CAP_PROP_FPS))
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) * 4  # Upscaled width
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * 4  # Upscaled height
fourcc = cv2.VideoWriter_fourcc(*"mp4v")  # Codec for output video
out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))

frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Convert frame to PIL Image
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    input_image = Image.fromarray(frame_rgb)

    # Upscale frame
    output_image = model.predict(input_image)

    # Convert back to OpenCV format
    output_frame = cv2.cvtColor(np.array(output_image), cv2.COLOR_RGB2BGR)

    # Write frame to output video
    out.write(output_frame)

    frame_count += 1
    print(f"Processed frame {frame_count}", end="\r")

    # Process frames in batches if necessary
    # If you find the script is running too slowly, consider batch processing and writing every N frames.

# Release resources
cap.release()
out.release()
print("Upscaling complete. Output saved as:", output_video_path)

